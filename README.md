## Sentiment Analysis Using Transformers (BERT Fine-Tuning)

This project demonstrates end-to-end sentiment classification using the Hugging Face Transformers library and PyTorch.
A pre-trained BERT-base-uncased model is fine-tuned on a custom Yelp-style review dataset to classify text as positive or negative.

The pipeline includes:

✔ Data preprocessing
✔ Tokenization using BERT tokenizer
✔ Custom PyTorch Dataset + DataLoader
✔ Model fine-tuning with AdamW + learning rate scheduling
✔ Evaluation on validation & test sets
✔ Inference on new reviews

## Model Performance

The fine-tuned BERT model achieves reliable accuracy in identifying sentiment from short and long reviews.
Below are sample predictions generated by the model:

## Example Predictions
Review: Hyderabad Biryani in the nearby restaurant is delicious
Predicted Sentiment: positive

Review: I am bad at cooking
Predicted Sentiment: negative

Review: I really got disappointed by the movie we watched last night
Predicted Sentiment: negative



## Technologies Used

Python

PyTorch

HuggingFace Transformers

BERT-base-uncased

Pandas, NumPy

Matplotlib & Seaborn (for EDA & plots)






